{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Developing FzTools\n",
    "draft: false\n",
    "date: 2025-05-12\n",
    "categories: [\"Dev-Journey\", \"Parallel\", \"Python\", \"fztools\"]\n",
    "author: F. L\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with `multiprocessing`\n",
    "\n",
    "::: {.callout-important}\n",
    "\n",
    "### in jupyternotebook\n",
    "\n",
    "multi-processing will throw error in jupyter notebook; the work around is define your function and then load it back to jupyter as a module;\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "**Use Case**\n",
    "\n",
    "1. Wait for a computation to complete before trigger automatically the next step\n",
    "2. A Depth first search algorithmn that let you share common memory of the same computations\n",
    "\n",
    "\n",
    "**Precaution**\n",
    "\n",
    "For multiprocessing to work with jupyter noteboook you have to define your function in modules rather than within the notebook itself;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "import defs\n",
    "import os\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Case Map Across Multiple Element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# creating processes\n",
    "p1 = Process(target=defs.print_square, args=(10, ))\n",
    "p2 = Process(target=defs.print_cube, args=(10, ))\n",
    "\n",
    "# starting process 1\n",
    "p1.start()\n",
    "# starting process 2\n",
    "p2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Case Set a Computation Aside\n",
    "\n",
    "Basically you can delay executing of some very large functio\n",
    "\n",
    "- pretend `worker1` and `worker2` is two very slow process\n",
    "- you can just setoff `worker1` and `worker2` to start working by itself while you compute something else;\n",
    "\n",
    "- to wait for computation to finish you use the `Process.join` method;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of process p1: 46583\n",
      "ID of process p2: 46584\n",
      "Cube: 1000\n",
      "Square: 100\n",
      "ID of process running worker1: 46583\n",
      "ID of process running worker2: 46584\n",
      "Both processes finished execution!\n",
      "Process p1 is alive: False\n",
      "Process p2 is alive: False\n"
     ]
    }
   ],
   "source": [
    "p1 =  Process(target=defs.worker1)\n",
    "p2 = Process(target=defs.worker2)\n",
    "\n",
    "# starting processes\n",
    "p1.start()\n",
    "p2.start()\n",
    "\n",
    "# process IDs: those can be worked while wait for completion\n",
    "print(\"ID of process p1: {}\".format(p1.pid))\n",
    "print(\"ID of process p2: {}\".format(p2.pid))\n",
    "\n",
    "# wait until processes are finished\n",
    "p1.join()\n",
    "p2.join()\n",
    "\n",
    "# both processes finished\n",
    "print(\"Both processes finished execution!\")\n",
    "\n",
    "# check if processes are alive\n",
    "print(\"Process p1 is alive: {}\".format(p1.is_alive()))\n",
    "print(\"Process p2 is alive: {}\".format(p2.is_alive()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a mutating variable `defs.result` defined as a module variable; something intuitive about this is it is a module variable pined to that module; so my function with the `global` will only ever stop there;\n",
    "\n",
    "```python\n",
    "# ./defs.py\n",
    "\n",
    "result = []\n",
    "\n",
    "def square_list(mylist): \n",
    "    \"\"\" \n",
    "    function to square a given list \n",
    "    \"\"\"\n",
    "    global result \n",
    "    # append squares of mylist to global list result \n",
    "    for num in mylist: \n",
    "        result.append(num * num) \n",
    "    # print global list result \n",
    "    print(\"Result(in process p1): {}\".format(result)) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(in process p1): [1, 4, 9, 16]\n",
      "\u001b[31mThe `result` list has not been modified correctly\u001b[39m\n",
      "\u001b[31m[]\u001b[39m\n",
      "\u001b[36mNow evaluate this function as normal\u001b[39m\n",
      "Result(in process p1): [1, 4, 9, 16]\n",
      "\u001b[36m[1, 4, 9, 16]\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "mylist = [1,2,3,4]\n",
    "\n",
    "import defs\n",
    "defs.result = []\n",
    "\n",
    "p1 = Process(target=defs.square_list, args=(mylist,)) \n",
    "# starting process \n",
    "p1.start() \n",
    "# wait until process is finished \n",
    "p1.join() \n",
    "\n",
    "try: \n",
    "    assert defs.result == [1, 4, 9, 16], \"The `result` list has not been modified correctly\"\n",
    "except AssertionError as e:\n",
    "    print(Fore.RED + str(e) + Fore.RESET)\n",
    "    print(Fore.RED + str(defs.result) + Fore.RESET)\n",
    "\n",
    "print(Fore.CYAN + \"Now evaluate this function as normal\" + Fore.RESET)\n",
    "defs.square_list(mylist)\n",
    "assert defs.result == [1, 4, 9, 16]\n",
    "print(Fore.CYAN + str(defs.result) + Fore.RESET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the the `result` variable has not been changed, because the process don't share the same memory space? \n",
    "\n",
    "![process-vs-memory](https://media.geeksforgeeks.org/wp-content/uploads/multiprocessing-python-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combat issue with shared memory space you have to use a special multiprocessing object;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(in process p1): [1, 4, 9, 16]\n",
      "Sum of squares(in process p1): 30\n",
      "Result(in main program): [1, 4, 9, 16]\n",
      "Sum of squares(in main program): 30\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "# creating Array of int data type with space for 4 integers \n",
    "result = multiprocessing.Array('i', 4) \n",
    "square_sum = multiprocessing.Value('i') \n",
    "\n",
    "p1 = Process(target=defs.square_list2, args=(mylist, result, square_sum)) \n",
    "p1.start() \n",
    "p1.join() \n",
    "\n",
    "print(\"Result(in main program): {}\".format(result[:])) \n",
    "print(\"Sum of squares(in main program): {}\".format(square_sum.value)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The Manager\n",
    "\n",
    "So now the \"passive function\" modify required object;\n",
    "\n",
    "```py\n",
    "# ./defs.py\n",
    "def print_records(records): \n",
    "    \"\"\" \n",
    "    function to print record(tuples) in records(list) \n",
    "    \"\"\"\n",
    "    for record in records: \n",
    "        print(\"Name: {0}\\nScore: {1}\\n\".format(record[0], record[1])) \n",
    "  \n",
    "def insert_record(record, records): \n",
    "    \"\"\" \n",
    "    function to add a new record to records(list) \n",
    "    \"\"\"\n",
    "    records.append(record) \n",
    "    print(\"New record added!\\n\") \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New record added!\n",
      "\n",
      "Name: Sam\n",
      "Score: 10\n",
      "\n",
      "Name: Adam\n",
      "Score: 9\n",
      "\n",
      "Name: Kevin\n",
      "Score: 9\n",
      "\n",
      "Name: Jeff\n",
      "Score: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with multiprocessing.Manager() as manager:\n",
    "    # creating a list in server process memory \n",
    "    records = manager.list([('Sam', 10), ('Adam', 9), ('Kevin',9)]) \n",
    "    # new record to be inserted in records \n",
    "    new_record = ('Jeff', 8) \n",
    "\n",
    "    # creating new processes \n",
    "    p1 = multiprocessing.Process(target=defs.insert_record, args=(new_record, records)) \n",
    "    p2 = multiprocessing.Process(target=defs.print_records, args=(records,)) \n",
    "\n",
    "    # running process p1 to insert new record \n",
    "    p1.start() \n",
    "    p1.join() \n",
    "\n",
    "    # running process p2 to print records \n",
    "    p2.start() \n",
    "    p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Que\" is a *communication* object\n",
    "\n",
    "\n",
    "::: {#figure-quer}\n",
    "\n",
    "![](https://media.geeksforgeeks.org/wp-content/uploads/multiprocessing-python-5.png){width=300}\n",
    "\n",
    "Concept illustartion by [geekforgeeks](https://www.geeksforgeeks.org/multiprocessing-python-set-2/)\n",
    ":::\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "#### Use `multiprocessing.Queue`\n",
    "\n",
    "A process can put object by using \"que.put\", then then another process can get it \"que.get\", but unlike a \"dict.get\", \"que.get\" remove the object from the list;\n",
    "\n",
    "```py\n",
    "# creating multiprocessing Queue \n",
    "q = multiprocessing.Queue() \n",
    "\n",
    "# access que\n",
    "# within function\n",
    "def foo():\n",
    "    q.put()\n",
    "\n",
    "def bar():\n",
    "    q.get()\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    "**Example**\n",
    "\n",
    "This example, one function will put stuff in for computation, the other will try access it;\n",
    "\n",
    "Define following function:\n",
    "\n",
    "```py\n",
    " \n",
    "def square_list(mylist, q): \n",
    "    \"\"\" \n",
    "    function to square a given list \n",
    "    \"\"\"\n",
    "    # append squares of mylist to queue \n",
    "    for num in mylist: \n",
    "        q.put(num * num) \n",
    "  \n",
    "def print_queue(q): \n",
    "    \"\"\" \n",
    "    function to print queue elements \n",
    "    \"\"\"\n",
    "    print(\"Queue elements:\") \n",
    "    while not q.empty(): \n",
    "        print(q.get()) \n",
    "    print(\"Queue is now empty!\") \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Process**\n",
    "This process will inject data into que first, and then access it in the scond process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square of 1 is 1\n",
      "Square of 2 is 4\n",
      "Square of 3 is 9\n",
      "Square of 4 is 16\n",
      "Queue elements:\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n",
      "Queue is now empty!\n"
     ]
    }
   ],
   "source": [
    "mylist = [1,2,3,4] \n",
    "  \n",
    "# creating multiprocessing Queue \n",
    "q = multiprocessing.Queue() \n",
    "\n",
    "# creating new processes \n",
    "p1 = multiprocessing.Process(target=defs.square_list3, args=(mylist, q)) \n",
    "p2 = multiprocessing.Process(target=defs.print_queue, args=(q,)) \n",
    "\n",
    "# running process p1 to square list \n",
    "p1.start()\n",
    "p1.join()\n",
    "# running process p2 to get queue elements \n",
    "p2.start()\n",
    "p2.join()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pipe to share between two process\n",
    "\n",
    "If the communication is two way it is said to prefer the \"Pipe\" object instead of a normal pipe\n",
    "\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "```\n",
    "parent_conn, child_conn = multiprocessing.Pipe()\n",
    "```\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "```py\n",
    "def sender(conn, msgs): \n",
    "    \"\"\" \n",
    "    function to send messages to other end of pipe \n",
    "    \"\"\"\n",
    "    for msg in msgs: \n",
    "        conn.send(msg) \n",
    "        print(\"Sent the message: {}\".format(msg)) \n",
    "    conn.close() \n",
    "  \n",
    "def receiver(conn): \n",
    "    \"\"\" \n",
    "    function to print the messages received from other \n",
    "    end of pipe \n",
    "    \"\"\"\n",
    "    while 1: \n",
    "        msg = conn.recv() \n",
    "        if msg == \"END\": \n",
    "            break\n",
    "        print(\"Received the message: {}\".format(msg)) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent the message: hello\n",
      "Sent the message: hey\n",
      "Sent the message: hru?\n",
      "Sent the message: END\n",
      "Received the message: hello\n",
      "Received the message: hey\n",
      "Received the message: hru?\n"
     ]
    }
   ],
   "source": [
    "msgs = [\"hello\", \"hey\", \"hru?\", \"END\"]\n",
    "# creating a pipe \n",
    "parent_conn, child_conn = multiprocessing.Pipe() \n",
    "\n",
    "# creating new processes \n",
    "p1 = multiprocessing.Process(target=defs.sender, args=(parent_conn,msgs )) \n",
    "p2 = multiprocessing.Process(target=defs.receiver, args=(child_conn,)) \n",
    "\n",
    "# running processes \n",
    "p1.start() \n",
    "p2.start() \n",
    "\n",
    "# wait until processes finish \n",
    "p1.join() \n",
    "p2.join() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lock a Process\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "### `multiprocessing.Lock()`\n",
    "\n",
    "This object is used again as outside; you acquire or release it within certain transaction;\n",
    "\n",
    "```py\n",
    "# define in function\n",
    "Lock = multiprocessing.Lock()\n",
    "\n",
    "# lock within object\n",
    "lock.acquire()\n",
    "# >> do stuff uninterupted\n",
    "locl.release()\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Asynsio IO\n",
    "\n",
    "Since javascript have similar process I think this is important API to learn;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage\n",
    "\n",
    "::: {.callout-caution}\n",
    "### use `asyncio.sleep()` for development\n",
    "If you just use the standard `time.sleep()` the whole process will sleep and there will be no parallel;\n",
    ":::\n",
    "\n",
    "::: {.callout-important}\n",
    "### use `nest_asyncio` for within jupyter notebook for development\n",
    "\n",
    "Standard pip install. Add this to your jupyter, await will work;\n",
    "```py\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A example that don't quite work;**\n",
    "\n",
    "Simply await an async function in the same process will be as if they are just what they are;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello (taken 2 seconds)\n",
      "hello2 (taken 1 second)\n",
      "The process took 3.00 s\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "\n",
    "async def main():\n",
    "    await asyncio.sleep(2)\n",
    "    print('hello (taken 2 seconds)')\n",
    "async def main2():\n",
    "    await asyncio.sleep(1)\n",
    "    print('hello2 (taken 1 second)')\n",
    "\n",
    "t1 = time.time()\n",
    "await main()\n",
    "await main2()\n",
    "t2 = time.time()\n",
    "print(\"The process took {_:.2f} s\".format(_=t2 - t1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's try make this work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello2 (taken 1 second)\n",
      "hello (taken 2 seconds)\n",
      "took 2.00 s\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "loop = asyncio.new_event_loop()\n",
    "tasks = [\n",
    "    loop.create_task(main()),\n",
    "    loop.create_task(main2())\n",
    "]\n",
    "\n",
    "t1 = time.time()\n",
    "loop.run_until_complete(asyncio.gather(*tasks))\n",
    "loop.close()\n",
    "t2 = time.time()\n",
    "print(\"took {:.2f} s\".format(t2-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In multi-processing**, this would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long_process2 done (taken 1 second)\n",
      "long_process1 done (taken 3 seconds)\n",
      "took 3.10 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from importlib import reload\n",
    "import multiprocessing\n",
    "import defs\n",
    "reload(defs)\n",
    "if __name__ == '__main__':\n",
    "    p1 = multiprocessing.Process(target=defs.long_process1)\n",
    "    p2 = multiprocessing.Process(target=defs.long_process2)\n",
    "\n",
    "    t1 = time.time()\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    t2 = time.time()\n",
    "    print(\"took {:.2f} s\".format(t2-t1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `asynsio` routine are:\n",
    "\n",
    "1. loop `.new_event_loop()`: create a loop object\n",
    "2. task `loop.create_task()`: create a task from asyncfunction\n",
    "3. gather `.gather([Task*])`: gather all the tasks\n",
    "4. run_until_complete `loop.run_until_complete`: run tasks\n",
    "5. close `loop.close()`: finally close this loop\n",
    "\n",
    "You can already thinking maybe with a context manager you can take out step1 and step3. But unfortunately **there are no context manager** for loop object (although there are alternative...hint).\n",
    "\n",
    "Fortunately a stack user has created one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OpenLoop:\n",
    "    \"\"\"\n",
    "    A context manager for open and close loops;\n",
    "    \"\"\"\n",
    "    def close(self,*args, **kwargs):\n",
    "        self._loop.stop()\n",
    "\n",
    "    def _close_wrapper(self):\n",
    "        self._close = self._loop.close  # close\n",
    "        self._loop.close = self.close\n",
    "\n",
    "    def __enter__(self):\n",
    "        self._loop = asyncio.new_event_loop()\n",
    "        self._close_wrapper()\n",
    "        return self._loop\n",
    "    \n",
    "    def __exit__(self,*exc_info):\n",
    "        asyncio.run(self._loop.shutdown_asyncgens())\n",
    "        asyncio.run(self._loop.shutdown_default_executor())\n",
    "        #close other services\n",
    "        self._close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a third way in `asyncio`\n",
    "\n",
    "### Aysnc task Group\n",
    "\n",
    "Turn out you don't create your task loop object, instead you use the default Taskgroup to create tasks that needs to be completed at the same time;\n",
    "\n",
    "::: {.callout-note}\n",
    "\n",
    "## Using `async with .. as` task group:\n",
    "\n",
    "* `async with`;\n",
    "* inside the task group you always evaluate your function;\n",
    "\n",
    "```py\n",
    "async with asyncio.TaskGroup() as tg:\n",
    "    tg.create_task(func_async())\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello2 (taken 1 second)\n",
      "hello (taken 2 seconds)\n",
      "--------------------------------------------------\n",
      "Time taken: 2.00 seconds\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from nest_asyncio import apply\n",
    "apply()\n",
    "async with asyncio.TaskGroup() as tg:\n",
    "\n",
    "    taskA = tg.create_task(main())\n",
    "    taskB = tg.create_task(main2())\n",
    "    t0 = time.time()\n",
    "    A = await taskA\n",
    "    B = await taskB\n",
    "    t1 = time.time()\n",
    "    print(\"-\"*50)\n",
    "    print(f'Time taken: {t1-t0:.2f} seconds')\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Perk: Auto Caching within same loop\n",
    "\n",
    "Another perk I have found is that async function will not recalculate your reuslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(make_A_normal): <class 'function'>\n",
      "type(make_A_async): <class 'function'>\n",
      "--------------------------------------------------\n",
      "Time taken: 2.00 seconds\n",
      "--------------------------------------------------\n",
      "\n",
      "Now lets try do it again with a for loop\n",
      "--------------------------------------------------\n",
      "Time taken: 0.00 seconds\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def make_A_normal():\n",
    "    return pd.DataFrame({'A': [1, 2, 3]})\n",
    "def make_B_normal():\n",
    "    return pd.DataFrame({'B': [4, 5, 6]})\n",
    "\n",
    "async def make_A_async():\n",
    "    await asyncio.sleep(1)\n",
    "    return make_A_normal()\n",
    "async def make_B_async():\n",
    "    await asyncio.sleep(2)\n",
    "    return make_B_normal()\n",
    "\n",
    "print(f'type(make_A_normal): {type(make_A_normal)}')\n",
    "print(f'type(make_A_async): {type(make_A_async)}')\n",
    "\n",
    " # first way to do it is just create a singular task\n",
    "with OpenLoop() as loop:\n",
    "   \n",
    "    tasks = [  loop.create_task(make_A_async())\n",
    "             , loop.create_task(make_B_async())]\n",
    "    \n",
    "    # call it till complete\n",
    "    t0 = time.time()\n",
    "    A, B = loop.run_until_complete(asyncio.gather(*tasks))\n",
    "    t1 = time.time()\n",
    "    print(\"-\"*50)\n",
    "    print(f'Time taken: {t1-t0:.2f} seconds')\n",
    "    print(\"-\"*50)\n",
    "    print(\"\\nNow lets try do it again with a for loop\")\n",
    "    t0 = time.time()\n",
    "    for task in tasks:\n",
    "        await task\n",
    "    t1 = time.time()\n",
    "    print(\"-\"*50)\n",
    "    print(f'Time taken: {t1-t0:.2f} seconds')\n",
    "    print(\"-\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at above! The second time took **zero** second!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply this to my `Stagemanager`\n",
    "\n",
    "\n",
    "\n",
    "OPTION 1: **Use `multiprocess.Manager`**\n",
    "\n",
    "\n",
    "Wrap my function in lambda for each target? We can see if we can wrap a dataframe in `manager`; \n",
    "the talk about manager maybe suited for processing two different dataframe? or any object?\n",
    "\n",
    "\n",
    "\n",
    "OPTION 2: **Could `apply_async` maybe something better to use just simply within each stage?**\n",
    "\n",
    "So far all my function resulted in somewhere else?\n",
    "\n",
    "```py\n",
    "from multiprocessing import Pool\n",
    "pool = Pool()\n",
    "result1 = pool.apply_async(solve1, [A])    # evaluate \"solve1(A)\" asynchronously\n",
    "result2 = pool.apply_async(solve2, [B])    # evaluate \"solve2(B)\" asynchronously\n",
    "answer1 = result1.get(timeout=10)\n",
    "answer2 = result2.get(timeout=10)\n",
    "```\n",
    "\n",
    "OPTION 3: **Use Component Graph** to split into several process and then combine them back?\n",
    "\n",
    "Also its possible to split into component? That means **there needs to be a method to convert the dependency graph into a Chain** object. \n",
    "\n",
    "OPTION 4: The `asyncio` implementation; that means we either have to write everything in await style, or def as normal let the python do the conversion;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concerning multi-processor’s memeory management system;**\n",
    "\n",
    "One drawback with multi-processor to me is share any class variables easily between different tasks don't seems as inuitive. A lot of give example will use python global scoping varible to demo; For understanding, I have to revisit python global variable scoping (I don't want when I create a package, those passive function will refuse to modify the variable I want to modify correctly);\n",
    "\n",
    "Revisiting Python Global Variable Scoping:\n",
    "\n",
    "> * ...if referencing variable outside function, it is okay (READONLY)\n",
    "> * ..to modify a variable outside function, you have to use the keyword **global**.\n",
    "> * ...but for mutable oject such as class, list dict you dont need specify global\n",
    "\n",
    "\n",
    "I’m not clear with how multi-processor produce a output variable and pass it to the next processor? right now it seems multi-processor is good for when you have a database and multiple user is trying to access this database? \n",
    "\n",
    "The best use case I can think of (involve passive function) is when you have a data pipeline run in cloud and bucket, and you would want those data pipeline to run in order, and directly mutate the object in a particular order (use que and lock) -- indeed, because copying the staging variable around could potentially cause a lot of data transfer/storage cost?\n",
    "\n",
    "**Paral computing with Async/Await**\n",
    "The syntax is very demure… but in somecases it don’t work as parallel, you have to await a task; hint: \n",
    "\n",
    "> * `asyncio.gather` |> `loop.run_until_complete`\n",
    "> * `await task`, `task = asyncio.create_task()`\n",
    "You also have to be carful because the you cannot process a sub fork by default. \n",
    "\n",
    "**My real problem is DAG**\n",
    "README from the open-source package to acheive this @sec-mayromr-async-dag\n",
    ", explain this really well (there is a issue with typing [^2]\n",
    "the package author has to use a lot of redundant code of typing things).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Edge Table For Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>source_ele</th>\n",
       "      <th>target_id</th>\n",
       "      <th>target_ele</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function plus_one at 0x10660aac0&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function power_two at 0x10660a160&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function sum_all at 0x10660aa20&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function plus_one at 0x10660aac0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;function power_two at 0x10660a160&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function sum_all at 0x10660aa20&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;function sum_all at 0x10660aa20&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id                           source_ele  target_id  \\\n",
       "0          0   <function plus_one at 0x10660aac0>          0   \n",
       "1          0  <function power_two at 0x10660a160>          0   \n",
       "2          1    <function sum_all at 0x10660aa20>          1   \n",
       "0         -1                                    A          0   \n",
       "1         -1                                    B          0   \n",
       "2          0                                    A          1   \n",
       "2          0                                    B          1   \n",
       "\n",
       "                            target_ele  \n",
       "0                                    A  \n",
       "1                                    B  \n",
       "2                                    C  \n",
       "0   <function plus_one at 0x10660aac0>  \n",
       "1  <function power_two at 0x10660a160>  \n",
       "2    <function sum_all at 0x10660aa20>  \n",
       "2    <function sum_all at 0x10660aa20>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fztools import StageManager\n",
    "\n",
    "stage1 = StageManager(\"stage1\")\n",
    "stage2 = StageManager(\"stage2\")\n",
    "@stage1.register(\"A\")\n",
    "def plus_one(a):\n",
    "    return a + 1\n",
    "\n",
    "@stage1.register(\"B\")\n",
    "def power_two(b):\n",
    "    return b * b\n",
    "\n",
    "@stage2.register(\"C\", [\"A\", \"B\"])\n",
    "def sum_all(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "chain = stage1 >> stage2\n",
    "chain.input = {\"A\": 1, \"B\": 2}\n",
    "chain.invoke()\n",
    "chain.output\n",
    "\n",
    "chain.edge_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_id</th>\n",
       "      <th>stage_name</th>\n",
       "      <th>output</th>\n",
       "      <th>prev_stage_id</th>\n",
       "      <th>inputs</th>\n",
       "      <th>func</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>stage</td>\n",
       "      <td>A</td>\n",
       "      <td>-1</td>\n",
       "      <td>[A]</td>\n",
       "      <td>&lt;function plus_one at 0x10660aac0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>stage</td>\n",
       "      <td>B</td>\n",
       "      <td>-1</td>\n",
       "      <td>[B]</td>\n",
       "      <td>&lt;function power_two at 0x10660a160&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>stage</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>[A, B]</td>\n",
       "      <td>&lt;function sum_all at 0x10660aa20&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stage_id stage_name output  prev_stage_id  inputs  \\\n",
       "0         0      stage      A             -1     [A]   \n",
       "1         0      stage      B             -1     [B]   \n",
       "2         1      stage      C              0  [A, B]   \n",
       "\n",
       "                                  func  \n",
       "0   <function plus_one at 0x10660aac0>  \n",
       "1  <function power_two at 0x10660a160>  \n",
       "2    <function sum_all at 0x10660aa20>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain.as_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': <function plus_one at 0x10660aac0>, 'B': <function power_two at 0x10660a160>}\n",
      "{'A': ['A'], 'B': ['B']}\n",
      "{'C': <function sum_all at 0x10660aa20>}\n",
      "{'C': ['A', 'B']}\n"
     ]
    }
   ],
   "source": [
    "stgs = chain.stages\n",
    "for stg in stgs:\n",
    "    print(stg.funcs)\n",
    "    print(stg.funcs_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few problem with this method; both because variable without a function registered will pass on as it is...\n",
    "But from `as_table` we can attempt to parase assign type;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n",
      "<class 'function'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': 1, 'B': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "def make_async_stage(stage):\n",
    "    funcs = stage.funcs\n",
    "    funcs_args = stage.funcs_args\n",
    "\n",
    "    async_stage_funcs = {}\n",
    "    for key, func in stage.funcs.items():\n",
    "        async def async_func(*args,**kwargs):\n",
    "            return func(*args,**kwargs)\n",
    "        async_stage_funcs[key] = async_func\n",
    "    return async_stage_funcs\n",
    "\n",
    "input_dict = {\"A\": 1, \"B\": 2}\n",
    "\n",
    "\n",
    "result = {}\n",
    "async_stage_funcs = make_async_stage(stage1)\n",
    "async with asyncio.TaskGroup() as tg:\n",
    "    for key, async_func in async_stage_funcs.items():\n",
    "        print(type(async_func))\n",
    "        arg = input_dict[key]\n",
    "        task = tg.create_task(async_func(arg))\n",
    "        d = await task\n",
    "        result[key] = d\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the problem became, how to wrap an unevaulated expectation? (Future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello ...\n",
      "... world\n"
     ]
    }
   ],
   "source": [
    "from nest_asyncio import apply\n",
    "import asyncio\n",
    "apply()\n",
    "async def set_after(fut, delay, value):\n",
    "    # Sleep for *delay* seconds.\n",
    "    await asyncio.sleep(delay)\n",
    "\n",
    "    # Set *value* as a result of *fut* Future.\n",
    "    fut.set_result(value)\n",
    "\n",
    "async def main():\n",
    "    # Get the current event loop.\n",
    "    loop = asyncio.get_running_loop()\n",
    "\n",
    "    # Create a new Future object.\n",
    "    fut = loop.create_future()\n",
    "\n",
    "    # Run \"set_after()\" coroutine in a parallel Task.\n",
    "    # We are using the low-level \"loop.create_task()\" API here because\n",
    "    # we already have a reference to the event loop at hand.\n",
    "    # Otherwise we could have just used \"asyncio.create_task()\".\n",
    "    loop.create_task(\n",
    "        set_after(fut, 1, '... world') )\n",
    "\n",
    "    print('hello ...')\n",
    "\n",
    "    # Wait until *fut* has a result (1 second) and print it.\n",
    "    print(await fut)\n",
    "\n",
    "asyncio.run(main())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The One I Need!\n",
    "\n",
    "Finally I have found a menimum example of establish coroutine based on something is done or not;\n",
    "This technical is essential dfs search all at the time;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to execute task 1 ...\n",
      "Start of task 1 ...\n",
      "Trying to execute task 2 ...\n",
      "Trying to execute task 3 ...\n",
      "Trying to execute task 4 ...\n",
      "Trying to execute task 5 ...\n",
      "... End of task 1\n",
      "Start of task 2 ...\n",
      "Start of task 5 ...\n",
      "... End of task 5\n",
      "... End of task 2\n",
      "Start of task 3 ...\n",
      "... End of task 3\n",
      "Start of task 4 ...\n",
      "... End of task 4\n",
      "... Finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from random import randrange\n",
    "# Helper function for the creation of simple sample coroutine\n",
    "def make_sample_coro(n):\n",
    "\n",
    "    async def coro():\n",
    "        print(f\"Start of task {n} ...\")\n",
    "        await asyncio.sleep(randrange(1, 5))\n",
    "        print(f\"... End of task {n}\")\n",
    "\n",
    "    return coro\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Simple graph in standard representation (node => neighbours)\n",
    "    graph = {1: {2, 5}, 2: {3}, 3: {4}, 4: set(), 5: {4}}\n",
    "    tasks = {n: make_sample_coro(n) for n in graph}\n",
    "    tasks_done = set()\n",
    "    \n",
    "    async def execute_task(ID):\n",
    "        print(f\"Trying to execute task {ID} ...\")\n",
    "        predecessors = {n for n, ns in graph.items() if ID in ns}\n",
    "        \n",
    "        while not predecessors <= tasks_done:  # Check if task can be started\n",
    "            await asyncio.sleep(0.1)\n",
    "        await tasks[ID]()\n",
    "        tasks_done.add(ID)\n",
    "    \n",
    "    await asyncio.gather(*[execute_task(n) for n in graph])\n",
    "    print(\"... Finished\")\n",
    "await main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is not a chain; because each node are run at the same time, so actually you only need to search the dependency up one level!\n",
    "\n",
    "It does not explicitly identify the graphical root; The root 1 would not have a dependency;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to esplain the set operator;\n",
    "assert {1} <= {1,2,3}\n",
    "assert {1,2,3} <= {1,2,3}\n",
    "assert ({1,2,3,4} <= {1,2,3}) == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- [Event Loop Runtime Error](https://stackoverflow.com/questions/46827007/error-runtimeerror-this-event-loop-is-already-running-in-python) -- came across this when try run sample code in jupyter notebook;\n",
    "- [Async Await Demo](https://stackoverflow.com/questions/50757497/simplest-async-await-example-possible-in-python): key takeaway is when writing a demo its better to use the `async.sleep` for time pulse.\n",
    "\n",
    "- *mayromr* Development Async DAG library: [mayromr/async-dag: A simple library for running complex DAG of async tasks](https://github.com/mayromr/async-dag/tree/main){#sec-mayromr-async-dag}\n",
    "    - A side issue of this is typing [TypeVarTuple Transformations Before Unpack · Issue \\#1216 · python/typing](https://github.com/python/typing/issues/1216)\n",
    "\n",
    "- [Original StackOverflow post contribute to DAG solution](https://stackoverflow.com/questions/78670718/how-to-execute-a-dag-of-tasks-using-async-io)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fztools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
